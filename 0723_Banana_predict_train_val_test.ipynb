{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "0723_Banana_predict_train_val_test",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "15T-UAC8u1QIEcE21gvJ32LVQumO74Zys",
      "authorship_tag": "ABX9TyNFKj1Rkib6Q3GYsJjMrbZm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yi-Wei-Lin/Tibame_ML_20210602/blob/main/0723_Banana_predict_train_val_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1kIpPvPSBU9"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n",
        "import os\n",
        "# past = lookback\n",
        "past = 30\n",
        "# dat = predict future day\n",
        "day = 3\n",
        "\n",
        "# 選擇train/test 切割日期\n",
        "train_date = \"2020-06-01\"\n",
        "test_date = \"2020-06-01\"\n",
        "\n",
        "# 選擇 train start 日期\n",
        "choice_date = False\n",
        "# choice_date = True\n",
        "start_date = \"2010-01-01\"\n",
        "\n",
        "# 選擇是否需要天氣\n",
        "# choice_w = False\n",
        "choice_w = True\n",
        "\n",
        "# 驗證資料切割%數\n",
        "val_split = 0.1\n",
        "\n",
        "# 選擇是否加入 price/volums diff value data\n",
        "# diff_value = False\n",
        "diff_value = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPrXqVawAaHV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ec69c1b-c92e-44fa-b162-803744c3a64f"
      },
      "source": [
        "if os.path.isfile(\"Banana_v2.xlsx\") == True:\n",
        "  pass\n",
        "else:\n",
        "  !wget \"https://github.com/Yi-Wei-Lin/Tibame_AI_Project/raw/main/userdata/Yi-Wei-Lin/dataset/Banana_v2.xlsx\"\n",
        "\n",
        "if os.path.isfile(\"reportdaily_mean_fillna.csv\") == True:\n",
        "  pass\n",
        "else:\n",
        "  !wget \"https://github.com/Yi-Wei-Lin/Tibame_AI_Project/raw/main/userdata/amoswu/dataset/reportdaily_mean_fillna.csv\"\n",
        "\n",
        "if os.path.isfile(\"TyphoonDatabase.csv\") == True:\n",
        "  pass\n",
        "else:\n",
        "  !wget \"https://github.com/Yi-Wei-Lin/Tibame_AI_Project/raw/main/userdata/amoswu/dataset/TyphoonDatabase.csv\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-07-23 08:22:15--  https://github.com/Yi-Wei-Lin/Tibame_AI_Project/raw/main/userdata/Yi-Wei-Lin/dataset/Cabbage_v2.xlsx\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/Yi-Wei-Lin/Tibame_AI_Project/main/userdata/Yi-Wei-Lin/dataset/Cabbage_v2.xlsx [following]\n",
            "--2021-07-23 08:22:15--  https://raw.githubusercontent.com/Yi-Wei-Lin/Tibame_AI_Project/main/userdata/Yi-Wei-Lin/dataset/Cabbage_v2.xlsx\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6911422 (6.6M) [application/octet-stream]\n",
            "Saving to: ‘Cabbage_v2.xlsx’\n",
            "\n",
            "Cabbage_v2.xlsx     100%[===================>]   6.59M  --.-KB/s    in 0.04s   \n",
            "\n",
            "2021-07-23 08:22:16 (164 MB/s) - ‘Cabbage_v2.xlsx’ saved [6911422/6911422]\n",
            "\n",
            "--2021-07-23 08:22:16--  https://github.com/Yi-Wei-Lin/Tibame_AI_Project/raw/main/userdata/amoswu/dataset/reportdaily_mean_fillna.csv\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/Yi-Wei-Lin/Tibame_AI_Project/main/userdata/amoswu/dataset/reportdaily_mean_fillna.csv [following]\n",
            "--2021-07-23 08:22:16--  https://raw.githubusercontent.com/Yi-Wei-Lin/Tibame_AI_Project/main/userdata/amoswu/dataset/reportdaily_mean_fillna.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 47969382 (46M) [text/plain]\n",
            "Saving to: ‘reportdaily_mean_fillna.csv’\n",
            "\n",
            "reportdaily_mean_fi 100%[===================>]  45.75M   281MB/s    in 0.2s    \n",
            "\n",
            "2021-07-23 08:22:16 (281 MB/s) - ‘reportdaily_mean_fillna.csv’ saved [47969382/47969382]\n",
            "\n",
            "--2021-07-23 08:22:16--  https://github.com/Yi-Wei-Lin/Tibame_AI_Project/raw/main/userdata/amoswu/dataset/TyphoonDatabase.csv\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/Yi-Wei-Lin/Tibame_AI_Project/main/userdata/amoswu/dataset/TyphoonDatabase.csv [following]\n",
            "--2021-07-23 08:22:16--  https://raw.githubusercontent.com/Yi-Wei-Lin/Tibame_AI_Project/main/userdata/amoswu/dataset/TyphoonDatabase.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 24275 (24K) [text/plain]\n",
            "Saving to: ‘TyphoonDatabase.csv’\n",
            "\n",
            "TyphoonDatabase.csv 100%[===================>]  23.71K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-07-23 08:22:17 (140 MB/s) - ‘TyphoonDatabase.csv’ saved [24275/24275]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZKFXXbuk8FOW",
        "outputId": "cd9c076d-358d-48a5-b0c3-0e84493c4824"
      },
      "source": [
        "city = {\n",
        "    '基隆市':'KLU',\n",
        "    '臺北市':'TPE',\n",
        "    '新北市':'TPH',\n",
        "    '桃園市':'TYC',\n",
        "    '新竹市':'HSC',\n",
        "    '新竹縣':'HSH',\n",
        "    '苗栗縣':'MAL',\n",
        "    '臺中市':'TXG',\n",
        "    '彰化縣':'CWH',\n",
        "    '南投縣':'NTO',\n",
        "    '雲林縣':'YLH',\n",
        "    '嘉義市':'CYI',\n",
        "    '嘉義縣':'CHY',\n",
        "    '臺南市':'TNN',\n",
        "    '高雄市':'KHH',\n",
        "    '屏東縣':'IUH',\n",
        "    '宜蘭縣':'ILN',\n",
        "    '花蓮縣':'HWA',\n",
        "    '臺東縣':'TTT'\n",
        "}\n",
        "df = pd.read_csv('reportdaily_mean_fillna.csv', encoding='utf-8')\n",
        "# 使用index做merge\n",
        "df_date = df['date'].drop_duplicates().to_frame().set_index('date')\n",
        "\n",
        "for cityname, citycode in city.items():\n",
        "    df_city = df.loc[df['city'] == cityname].add_suffix('_' + citycode).set_index('date' + '_' + citycode)\n",
        "    df_date = pd.merge(df_date, df_city, how='left', left_index = True, right_index = True)\n",
        "\n",
        "df_date.to_csv('all.csv', encoding='utf-8')\n",
        "typhoon_df = pd.read_csv('TyphoonDatabase.csv', encoding='utf-8')\n",
        "weather_df = pd.read_csv('all.csv', encoding='utf-8')\n",
        "weather_df['WarnMark'] = 0\n",
        "# 警報日期處理\n",
        "import datetime\n",
        "\n",
        "period_ctrl = 0 # 颱風警報期間控制\n",
        "warn_mark = list()\n",
        "\n",
        "for wd in typhoon_df['Warning']:\n",
        "  start = datetime.datetime.strptime(wd[0:10], '%Y-%m-%d')\n",
        "  end = datetime.datetime.strptime(wd[17:27], '%Y-%m-%d')\n",
        "  period = end - start\n",
        "  # print(period.days)\n",
        "  \n",
        "  ctrl_start = start\n",
        "  i = 0\n",
        "  \n",
        "  warn_mark.append(wd[0:10])\n",
        "  while i < period.days:\n",
        "    start = start + datetime.timedelta(days=1)\n",
        "    warn_mark.append(datetime.datetime.strftime(start, '%Y-%m-%d'))\n",
        "    i = i + 1\n",
        "  warn_mark.append(wd[17:27])\n",
        "\n",
        "  if period_ctrl != 0:\n",
        "    j = 0\n",
        "    while j < period_ctrl:\n",
        "      ctrl_start = ctrl_start - datetime.timedelta(days=1)\n",
        "      warn_mark.append(datetime.datetime.strftime(ctrl_start, '%Y-%m-%d'))\n",
        "      j = j + 1\n",
        "\n",
        "unique_set = set(warn_mark)\n",
        "unique_list = list(unique_set)\n",
        "warn_mark = list()\n",
        "warn_mark = unique_list\n",
        "import csv\n",
        "\n",
        "weather_list = weather_df.values.tolist()\n",
        "\n",
        "with open('dataset.csv', 'w', newline='') as csvfile:\n",
        "  writer = csv.writer(csvfile)\n",
        "  \n",
        "  writer.writerow(['date','city_KLU','StnPres_KLU','SeaPres_KLU','StnPresMax_KLU','StnPresMaxTime_KLU','StnPresMin_KLU','StnPresMinTime_KLU','Temperature_KLU','TMax_KLU','TMaxTime_KLU','TMin_KLU','TMinTime_KLU','TdDewPoint_KLU','RH_KLU','RHMin_KLU','RHMinTime_KLU','WS_KLU','WD_KLU','WSGust_KLU','WDGust_KLU','WGustTime_KLU','Precp_KLU','PrecpHour_KLU','PrecpMax10_KLU','PrecpMax10Time_KLU','PrecpMax60_KLU','PrecpMax60Time_KLU','SunShine_KLU','SunShineRate_KLU','GloblRad_KLU','VisbMean_KLU','EvapA_KLU','UVIMax_KLU','UVIMaxTime_KLU','CloudAmount_KLU','city_TPE','StnPres_TPE','SeaPres_TPE','StnPresMax_TPE','StnPresMaxTime_TPE','StnPresMin_TPE','StnPresMinTime_TPE','Temperature_TPE','TMax_TPE','TMaxTime_TPE','TMin_TPE','TMinTime_TPE','TdDewPoint_TPE','RH_TPE','RHMin_TPE','RHMinTime_TPE','WS_TPE','WD_TPE','WSGust_TPE','WDGust_TPE','WGustTime_TPE','Precp_TPE','PrecpHour_TPE','PrecpMax10_TPE','PrecpMax10Time_TPE','PrecpMax60_TPE','PrecpMax60Time_TPE','SunShine_TPE','SunShineRate_TPE','GloblRad_TPE','VisbMean_TPE','EvapA_TPE','UVIMax_TPE','UVIMaxTime_TPE','CloudAmount_TPE','city_TPH','StnPres_TPH','SeaPres_TPH','StnPresMax_TPH','StnPresMaxTime_TPH','StnPresMin_TPH','StnPresMinTime_TPH','Temperature_TPH','TMax_TPH','TMaxTime_TPH','TMin_TPH','TMinTime_TPH','TdDewPoint_TPH','RH_TPH','RHMin_TPH','RHMinTime_TPH','WS_TPH','WD_TPH','WSGust_TPH','WDGust_TPH','WGustTime_TPH','Precp_TPH','PrecpHour_TPH','PrecpMax10_TPH','PrecpMax10Time_TPH','PrecpMax60_TPH','PrecpMax60Time_TPH','SunShine_TPH','SunShineRate_TPH','GloblRad_TPH','VisbMean_TPH','EvapA_TPH','UVIMax_TPH','UVIMaxTime_TPH','CloudAmount_TPH','city_TYC','StnPres_TYC','SeaPres_TYC','StnPresMax_TYC','StnPresMaxTime_TYC','StnPresMin_TYC','StnPresMinTime_TYC','Temperature_TYC','TMax_TYC','TMaxTime_TYC','TMin_TYC','TMinTime_TYC','TdDewPoint_TYC','RH_TYC','RHMin_TYC','RHMinTime_TYC','WS_TYC','WD_TYC','WSGust_TYC','WDGust_TYC','WGustTime_TYC','Precp_TYC','PrecpHour_TYC','PrecpMax10_TYC','PrecpMax10Time_TYC','PrecpMax60_TYC','PrecpMax60Time_TYC','SunShine_TYC','SunShineRate_TYC','GloblRad_TYC','VisbMean_TYC','EvapA_TYC','UVIMax_TYC','UVIMaxTime_TYC','CloudAmount_TYC','city_HSC','StnPres_HSC','SeaPres_HSC','StnPresMax_HSC','StnPresMaxTime_HSC','StnPresMin_HSC','StnPresMinTime_HSC','Temperature_HSC','TMax_HSC','TMaxTime_HSC','TMin_HSC','TMinTime_HSC','TdDewPoint_HSC','RH_HSC','RHMin_HSC','RHMinTime_HSC','WS_HSC','WD_HSC','WSGust_HSC','WDGust_HSC','WGustTime_HSC','Precp_HSC','PrecpHour_HSC','PrecpMax10_HSC','PrecpMax10Time_HSC','PrecpMax60_HSC','PrecpMax60Time_HSC','SunShine_HSC','SunShineRate_HSC','GloblRad_HSC','VisbMean_HSC','EvapA_HSC','UVIMax_HSC','UVIMaxTime_HSC','CloudAmount_HSC','city_HSH','StnPres_HSH','SeaPres_HSH','StnPresMax_HSH','StnPresMaxTime_HSH','StnPresMin_HSH','StnPresMinTime_HSH','Temperature_HSH','TMax_HSH','TMaxTime_HSH','TMin_HSH','TMinTime_HSH','TdDewPoint_HSH','RH_HSH','RHMin_HSH','RHMinTime_HSH','WS_HSH','WD_HSH','WSGust_HSH','WDGust_HSH','WGustTime_HSH','Precp_HSH','PrecpHour_HSH','PrecpMax10_HSH','PrecpMax10Time_HSH','PrecpMax60_HSH','PrecpMax60Time_HSH','SunShine_HSH','SunShineRate_HSH','GloblRad_HSH','VisbMean_HSH','EvapA_HSH','UVIMax_HSH','UVIMaxTime_HSH','CloudAmount_HSH','city_MAL','StnPres_MAL','SeaPres_MAL','StnPresMax_MAL','StnPresMaxTime_MAL','StnPresMin_MAL','StnPresMinTime_MAL','Temperature_MAL','TMax_MAL','TMaxTime_MAL','TMin_MAL','TMinTime_MAL','TdDewPoint_MAL','RH_MAL','RHMin_MAL','RHMinTime_MAL','WS_MAL','WD_MAL','WSGust_MAL','WDGust_MAL','WGustTime_MAL','Precp_MAL','PrecpHour_MAL','PrecpMax10_MAL','PrecpMax10Time_MAL','PrecpMax60_MAL','PrecpMax60Time_MAL','SunShine_MAL','SunShineRate_MAL','GloblRad_MAL','VisbMean_MAL','EvapA_MAL','UVIMax_MAL','UVIMaxTime_MAL','CloudAmount_MAL','city_TXG','StnPres_TXG','SeaPres_TXG','StnPresMax_TXG','StnPresMaxTime_TXG','StnPresMin_TXG','StnPresMinTime_TXG','Temperature_TXG','TMax_TXG','TMaxTime_TXG','TMin_TXG','TMinTime_TXG','TdDewPoint_TXG','RH_TXG','RHMin_TXG','RHMinTime_TXG','WS_TXG','WD_TXG','WSGust_TXG','WDGust_TXG','WGustTime_TXG','Precp_TXG','PrecpHour_TXG','PrecpMax10_TXG','PrecpMax10Time_TXG','PrecpMax60_TXG','PrecpMax60Time_TXG','SunShine_TXG','SunShineRate_TXG','GloblRad_TXG','VisbMean_TXG','EvapA_TXG','UVIMax_TXG','UVIMaxTime_TXG','CloudAmount_TXG','city_CWH','StnPres_CWH','SeaPres_CWH','StnPresMax_CWH','StnPresMaxTime_CWH','StnPresMin_CWH','StnPresMinTime_CWH','Temperature_CWH','TMax_CWH','TMaxTime_CWH','TMin_CWH','TMinTime_CWH','TdDewPoint_CWH','RH_CWH','RHMin_CWH','RHMinTime_CWH','WS_CWH','WD_CWH','WSGust_CWH','WDGust_CWH','WGustTime_CWH','Precp_CWH','PrecpHour_CWH','PrecpMax10_CWH','PrecpMax10Time_CWH','PrecpMax60_CWH','PrecpMax60Time_CWH','SunShine_CWH','SunShineRate_CWH','GloblRad_CWH','VisbMean_CWH','EvapA_CWH','UVIMax_CWH','UVIMaxTime_CWH','CloudAmount_CWH','city_NTO','StnPres_NTO','SeaPres_NTO','StnPresMax_NTO','StnPresMaxTime_NTO','StnPresMin_NTO','StnPresMinTime_NTO','Temperature_NTO','TMax_NTO','TMaxTime_NTO','TMin_NTO','TMinTime_NTO','TdDewPoint_NTO','RH_NTO','RHMin_NTO','RHMinTime_NTO','WS_NTO','WD_NTO','WSGust_NTO','WDGust_NTO','WGustTime_NTO','Precp_NTO','PrecpHour_NTO','PrecpMax10_NTO','PrecpMax10Time_NTO','PrecpMax60_NTO','PrecpMax60Time_NTO','SunShine_NTO','SunShineRate_NTO','GloblRad_NTO','VisbMean_NTO','EvapA_NTO','UVIMax_NTO','UVIMaxTime_NTO','CloudAmount_NTO','city_YLH','StnPres_YLH','SeaPres_YLH','StnPresMax_YLH','StnPresMaxTime_YLH','StnPresMin_YLH','StnPresMinTime_YLH','Temperature_YLH','TMax_YLH','TMaxTime_YLH','TMin_YLH','TMinTime_YLH','TdDewPoint_YLH','RH_YLH','RHMin_YLH','RHMinTime_YLH','WS_YLH','WD_YLH','WSGust_YLH','WDGust_YLH','WGustTime_YLH','Precp_YLH','PrecpHour_YLH','PrecpMax10_YLH','PrecpMax10Time_YLH','PrecpMax60_YLH','PrecpMax60Time_YLH','SunShine_YLH','SunShineRate_YLH','GloblRad_YLH','VisbMean_YLH','EvapA_YLH','UVIMax_YLH','UVIMaxTime_YLH','CloudAmount_YLH','city_CYI','StnPres_CYI','SeaPres_CYI','StnPresMax_CYI','StnPresMaxTime_CYI','StnPresMin_CYI','StnPresMinTime_CYI','Temperature_CYI','TMax_CYI','TMaxTime_CYI','TMin_CYI','TMinTime_CYI','TdDewPoint_CYI','RH_CYI','RHMin_CYI','RHMinTime_CYI','WS_CYI','WD_CYI','WSGust_CYI','WDGust_CYI','WGustTime_CYI','Precp_CYI','PrecpHour_CYI','PrecpMax10_CYI','PrecpMax10Time_CYI','PrecpMax60_CYI','PrecpMax60Time_CYI','SunShine_CYI','SunShineRate_CYI','GloblRad_CYI','VisbMean_CYI','EvapA_CYI','UVIMax_CYI','UVIMaxTime_CYI','CloudAmount_CYI','city_CHY','StnPres_CHY','SeaPres_CHY','StnPresMax_CHY','StnPresMaxTime_CHY','StnPresMin_CHY','StnPresMinTime_CHY','Temperature_CHY','TMax_CHY','TMaxTime_CHY','TMin_CHY','TMinTime_CHY','TdDewPoint_CHY','RH_CHY','RHMin_CHY','RHMinTime_CHY','WS_CHY','WD_CHY','WSGust_CHY','WDGust_CHY','WGustTime_CHY','Precp_CHY','PrecpHour_CHY','PrecpMax10_CHY','PrecpMax10Time_CHY','PrecpMax60_CHY','PrecpMax60Time_CHY','SunShine_CHY','SunShineRate_CHY','GloblRad_CHY','VisbMean_CHY','EvapA_CHY','UVIMax_CHY','UVIMaxTime_CHY','CloudAmount_CHY','city_TNN','StnPres_TNN','SeaPres_TNN','StnPresMax_TNN','StnPresMaxTime_TNN','StnPresMin_TNN','StnPresMinTime_TNN','Temperature_TNN','TMax_TNN','TMaxTime_TNN','TMin_TNN','TMinTime_TNN','TdDewPoint_TNN','RH_TNN','RHMin_TNN','RHMinTime_TNN','WS_TNN','WD_TNN','WSGust_TNN','WDGust_TNN','WGustTime_TNN','Precp_TNN','PrecpHour_TNN','PrecpMax10_TNN','PrecpMax10Time_TNN','PrecpMax60_TNN','PrecpMax60Time_TNN','SunShine_TNN','SunShineRate_TNN','GloblRad_TNN','VisbMean_TNN','EvapA_TNN','UVIMax_TNN','UVIMaxTime_TNN','CloudAmount_TNN','city_KHH','StnPres_KHH','SeaPres_KHH','StnPresMax_KHH','StnPresMaxTime_KHH','StnPresMin_KHH','StnPresMinTime_KHH','Temperature_KHH','TMax_KHH','TMaxTime_KHH','TMin_KHH','TMinTime_KHH','TdDewPoint_KHH','RH_KHH','RHMin_KHH','RHMinTime_KHH','WS_KHH','WD_KHH','WSGust_KHH','WDGust_KHH','WGustTime_KHH','Precp_KHH','PrecpHour_KHH','PrecpMax10_KHH','PrecpMax10Time_KHH','PrecpMax60_KHH','PrecpMax60Time_KHH','SunShine_KHH','SunShineRate_KHH','GloblRad_KHH','VisbMean_KHH','EvapA_KHH','UVIMax_KHH','UVIMaxTime_KHH','CloudAmount_KHH','city_IUH','StnPres_IUH','SeaPres_IUH','StnPresMax_IUH','StnPresMaxTime_IUH','StnPresMin_IUH','StnPresMinTime_IUH','Temperature_IUH','TMax_IUH','TMaxTime_IUH','TMin_IUH','TMinTime_IUH','TdDewPoint_IUH','RH_IUH','RHMin_IUH','RHMinTime_IUH','WS_IUH','WD_IUH','WSGust_IUH','WDGust_IUH','WGustTime_IUH','Precp_IUH','PrecpHour_IUH','PrecpMax10_IUH','PrecpMax10Time_IUH','PrecpMax60_IUH','PrecpMax60Time_IUH','SunShine_IUH','SunShineRate_IUH','GloblRad_IUH','VisbMean_IUH','EvapA_IUH','UVIMax_IUH','UVIMaxTime_IUH','CloudAmount_IUH','city_ILN','StnPres_ILN','SeaPres_ILN','StnPresMax_ILN','StnPresMaxTime_ILN','StnPresMin_ILN','StnPresMinTime_ILN','Temperature_ILN','TMax_ILN','TMaxTime_ILN','TMin_ILN','TMinTime_ILN','TdDewPoint_ILN','RH_ILN','RHMin_ILN','RHMinTime_ILN','WS_ILN','WD_ILN','WSGust_ILN','WDGust_ILN','WGustTime_ILN','Precp_ILN','PrecpHour_ILN','PrecpMax10_ILN','PrecpMax10Time_ILN','PrecpMax60_ILN','PrecpMax60Time_ILN','SunShine_ILN','SunShineRate_ILN','GloblRad_ILN','VisbMean_ILN','EvapA_ILN','UVIMax_ILN','UVIMaxTime_ILN','CloudAmount_ILN','city_HWA','StnPres_HWA','SeaPres_HWA','StnPresMax_HWA','StnPresMaxTime_HWA','StnPresMin_HWA','StnPresMinTime_HWA','Temperature_HWA','TMax_HWA','TMaxTime_HWA','TMin_HWA','TMinTime_HWA','TdDewPoint_HWA','RH_HWA','RHMin_HWA','RHMinTime_HWA','WS_HWA','WD_HWA','WSGust_HWA','WDGust_HWA','WGustTime_HWA','Precp_HWA','PrecpHour_HWA','PrecpMax10_HWA','PrecpMax10Time_HWA','PrecpMax60_HWA','PrecpMax60Time_HWA','SunShine_HWA','SunShineRate_HWA','GloblRad_HWA','VisbMean_HWA','EvapA_HWA','UVIMax_HWA','UVIMaxTime_HWA','CloudAmount_HWA','city_TTT','StnPres_TTT','SeaPres_TTT','StnPresMax_TTT','StnPresMaxTime_TTT','StnPresMin_TTT','StnPresMinTime_TTT','Temperature_TTT','TMax_TTT','TMaxTime_TTT','TMin_TTT','TMinTime_TTT','TdDewPoint_TTT','RH_TTT','RHMin_TTT','RHMinTime_TTT','WS_TTT','WD_TTT','WSGust_TTT','WDGust_TTT','WGustTime_TTT','Precp_TTT','PrecpHour_TTT','PrecpMax10_TTT','PrecpMax10Time_TTT','PrecpMax60_TTT','PrecpMax60Time_TTT','SunShine_TTT','SunShineRate_TTT','GloblRad_TTT','VisbMean_TTT','EvapA_TTT','UVIMax_TTT','UVIMaxTime_TTT','CloudAmount_TTT','WarnMark'])\n",
        "\n",
        "  for wl in weather_list:\n",
        "    f = 0\n",
        "    for wm in warn_mark:\n",
        "      if wl[0] == wm:\n",
        "        wl[666] = 1\n",
        "        writer.writerow(wl)\n",
        "        f = 1\n",
        "    if f == 0:\n",
        "      writer.writerow(wl)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (130,132,305,307) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fNFBa0VTW1i"
      },
      "source": [
        "data = pd.read_excel(\"Banana_v2.xlsx\")\n",
        "data_w = pd.read_csv(\"dataset.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7f0m6yN3elvl"
      },
      "source": [
        "if diff_value == True:\n",
        "  data[\"Avg_price_diff\"] = data[\"Avg_price_diff\"].fillna(0)\n",
        "  data[\"Volume_diff\"] = data[\"Volume_diff\"].fillna(0)\n",
        "else:\n",
        "  data = data.drop([\"Avg_price_diff\"], axis=1)\n",
        "  data = data.drop([\"Volume_diff\"], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGTulNNan9Eg"
      },
      "source": [
        "drop_name = [\"city_\", \"StnPresMaxTime_\", \"StnPresMinTime_\", \"TMaxTime_\", \"TMinTime_\", \"RHMinTime_\", \"WGustTime_\", \"PrecpMax10Time_\", \"PrecpMax60Time_\", \"UVIMaxTime_\"]\n",
        "city = [\n",
        "    'KLU',\n",
        "    'TPE',\n",
        "    'TPH',\n",
        "    'TYC',\n",
        "    'HSC',\n",
        "    'HSH',\n",
        "    'MAL',\n",
        "    'TXG',\n",
        "    'CWH',\n",
        "    'NTO',\n",
        "    'YLH',\n",
        "    'CYI',\n",
        "    'CHY',\n",
        "    'TNN',\n",
        "    'KHH',\n",
        "    'IUH',\n",
        "    'ILN',\n",
        "    'HWA',\n",
        "    'TTT'\n",
        "]\n",
        "drop = []\n",
        "for c in city:\n",
        "  for n in drop_name:\n",
        "    drop.append(n+c)\n",
        "data_w = data_w.drop(drop, axis=1).dropna()\n",
        "data_w = data_w.rename(columns={'date':'Date'})\n",
        "data_w[\"Date\"] = pd.to_datetime(data_w[\"Date\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJ3h7hWdT2l7"
      },
      "source": [
        "data = data.dropna()\n",
        "data = data.loc[data[\"Market\"] == \"台北一\"]\n",
        "np.array(data[\"Avg_price\"]).reshape(-1,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Q-tmUMh9hab"
      },
      "source": [
        "if choice_w == True:\n",
        "  data = pd.merge(data,data_w,how=\"left\", on=\"Date\").dropna()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-e9EOm0WIuS"
      },
      "source": [
        "data = data.reset_index()\n",
        "data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51xZpmvevw65"
      },
      "source": [
        "# data_dum = pd.get_dummies(data)\n",
        "# pd.DataFrame(data_dum)\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "onehotencoder = OneHotEncoder()\n",
        "data_str_ohe=onehotencoder.fit_transform(data[[\"Month\"]]).toarray()\n",
        "month = pd.DataFrame(data_str_ohe)\n",
        "for i in month:\n",
        "  new = int(i) + 1\n",
        "  new = str(new)\n",
        "  month = month.rename(columns={i:new})\n",
        "month = month.add_prefix(\"Month_\")\n",
        "data = data.join(month, how=\"left\")\n",
        "# df.loc[df['city'] == '基隆市'].add_suffix('_' + 'KLU')\n",
        "# df.rename(columns={'舊欄位名稱': '新欄位名稱'}) .add_prefix(\"Month_\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQ4k8Y4zwiP2"
      },
      "source": [
        "onehotencoder = OneHotEncoder()\n",
        "data_str_ohe=onehotencoder.fit_transform(data[[\"Week_day\"]]).toarray()\n",
        "month = pd.DataFrame(data_str_ohe)\n",
        "for i in month:\n",
        "  new = int(i) + 1\n",
        "  new = str(new)\n",
        "  month = month.rename(columns={i:new})\n",
        "month = month.add_prefix(\"Week_day_\")\n",
        "data = data.join(month, how=\"left\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwR2iq4ZCz_7"
      },
      "source": [
        "onehotencoder = OneHotEncoder()\n",
        "data_str_ohe=onehotencoder.fit_transform(data[[\"Year\"]]).toarray()\n",
        "month = pd.DataFrame(data_str_ohe)\n",
        "for i in month:\n",
        "  new = int(i) + data[\"Year\"].iloc[0]\n",
        "  new = str(new)\n",
        "  month = month.rename(columns={i:new})\n",
        "month = month.add_prefix(\"Year_\")\n",
        "data = data.join(month, how=\"left\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XVV3ok9Cbwt"
      },
      "source": [
        "data_train = data[data[\"Date\"] < \"2020-06-01\"]\n",
        "if choice_date == True:\n",
        "  data_train = data_train[data_train[\"Date\"] > start_date]\n",
        "data_test = data[data[\"Date\"] >= \"2020-06-01\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFoLA9sNtyOq"
      },
      "source": [
        "data_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHkweN_gW84H"
      },
      "source": [
        "data_train = data_train.drop([\"index\", \"Date\",\"Market\", \"Product\", \"Month\", \"Week_day\", \"Year\", \"Rest_day\"], axis=1)\n",
        "data_test = data_test.drop([\"index\", \"Date\",\"Market\", \"Product\", \"Month\", \"Week_day\", \"Year\", \"Rest_day\"], axis=1)\n",
        "data_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JO-5YfElYQcK"
      },
      "source": [
        "# from tensorflow.keras.utils import to_categorical\n",
        "# pd.DataFrame(to_categorical(data_train[\"Month\"]))\n",
        "feature = data_train.shape[1]\n",
        "print(feature)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4gbwyjmUNvKM"
      },
      "source": [
        "len_data = len(data_train)\n",
        "len_train = int(len_data*(1-val_split))\n",
        "len_val = (len_data-len_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2r2gjFUO39u"
      },
      "source": [
        "print(len_data)\n",
        "print(len_train)\n",
        "print(len_val)\n",
        "print(len_train + len_val)\n",
        "data_val = data_train[len_train:]\n",
        "data_train = data_train[0:len_train]\n",
        "data_val_past = data_val.tail(past+day-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fszyjGjvsY7z"
      },
      "source": [
        "data_test = data_val_past.append(data_test)\n",
        "data_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "buVZWLuxugIA"
      },
      "source": [
        "# preparing label data\n",
        "Cabbage_shift = data_train.shift(-day)\n",
        "label = Cabbage_shift['Avg_price']\n",
        "\n",
        "# adjusting the shape of both\n",
        "data_train = data_train.drop(data_train.index[len(data_train)-day:], axis=0)\n",
        "label = label.drop(label.index[len(label)-day:], axis=0)\n",
        "\n",
        "# conversion to numpy array\n",
        "x, y = data_train.values, label.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFguS7T1RWLr"
      },
      "source": [
        "# preparing label data\n",
        "Cabbage_shift = data_val.shift(-day)\n",
        "label = Cabbage_shift['Avg_price']\n",
        "\n",
        "# adjusting the shape of both\n",
        "data_val = data_val.drop(data_val.index[len(data_val)-day:], axis=0)\n",
        "label = label.drop(label.index[len(label)-day:], axis=0)\n",
        "\n",
        "# conversion to numpy array\n",
        "x_val, y_val = data_val.values, label.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNMPa0cEuMET"
      },
      "source": [
        "# Cabbage_shift = data_test.shift(-day)\n",
        "label = data_test['Avg_price']\n",
        "\n",
        "# adjusting the shape of both\n",
        "# data_test = data_test.drop(data_test.index[len(data_test)-day:], axis=0)\n",
        "# label = label.drop(label.index[len(label)-day:], axis=0)\n",
        "\n",
        "\n",
        "# conversion to numpy array\n",
        "gg, yy = data_test.values, label.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_kZM-707Bp2"
      },
      "source": [
        "X = []\n",
        "for i in range(len(data_train)-past-day+1):\n",
        "  xx = []\n",
        "  for d in range(past):\n",
        "    xx.append(data_train.iloc[i+d])\n",
        "  X.append(xx)\n",
        "X = np.array(X)\n",
        "x_train = X\n",
        "y_train = y[past-1:-day]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ar-CvbvSB-s"
      },
      "source": [
        "X = []\n",
        "for i in range(len(data_val)-past-day+1):\n",
        "  xx = []\n",
        "  for d in range(past):\n",
        "    xx.append(data_val.iloc[i+d])\n",
        "  X.append(xx)\n",
        "X = np.array(X)\n",
        "x_val = X\n",
        "y_val = y_val[past-1:-day]\n",
        "y_real = y_val"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZA5MEP-3uj42"
      },
      "source": [
        "X = []\n",
        "for i in range(len(data_test)-past-day+1):\n",
        "  xx = []\n",
        "  for d in range(past):\n",
        "    xx.append(data_test.iloc[i+d])\n",
        "  X.append(xx)\n",
        "X = np.array(X)\n",
        "gg = X\n",
        "yy = yy[past+day-1:]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpCb-VIyIu5w"
      },
      "source": [
        "print(gg.shape)\n",
        "gg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZ0tpDZtXt5M"
      },
      "source": [
        "print(yy.shape)\n",
        "yy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0p2fqLHG2S8"
      },
      "source": [
        "x_shape = x_train.shape[0]\n",
        "x_val_shape = x_val.shape[0]\n",
        "x_train = x_train.reshape(-1,feature)\n",
        "x_val = x_val.reshape(-1,feature)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eH8C9tL6P5nE"
      },
      "source": [
        "Xscaler = MinMaxScaler()\n",
        "Yscaler = MinMaxScaler()\n",
        "x_train = Xscaler.fit_transform(x_train)\n",
        "y_train = Yscaler.fit_transform(y_train.reshape(-1,1))\n",
        "x_val = Xscaler.transform(x_val)\n",
        "y_val = Yscaler.transform(y_val.reshape(-1,1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7eqPM1dHg3A"
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hEfLzqLYxcc9"
      },
      "source": [
        "# splitting train and test\n",
        "# x_train = x_train.reshape((-1,1,5))\n",
        "x_train = x_train.reshape((-1,past,feature))\n",
        "x_val = x_val.reshape((-1,past,feature))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSgBUOoxak0-"
      },
      "source": [
        "# Building LSTM model\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, GRU, BatchNormalization\n",
        "layers = [\n",
        "    LSTM(units=32, return_sequences=True, input_shape=(x_train.shape[1], x_train.shape[2])),\n",
        "    Dropout(0.2),\n",
        "    LSTM(units=64, return_sequences=True),\n",
        "    Dropout(0.2),\n",
        "    # BatchNormalization(),\n",
        "    # LSTM(units=128, return_sequences=True),\n",
        "    # Dropout(0.2),\n",
        "    # BatchNormalization(),\n",
        "    LSTM(units=128),\n",
        "    # Dropout(0.2),\n",
        "    Dense(units=10, activation=\"sigmoid\"),\n",
        "    Dense(units=1)\n",
        "]\n",
        "regressor = Sequential(layers)\n",
        "regressor.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVYzbTuYjvDo"
      },
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import MeanSquaredError, BinaryCrossentropy, CategoricalCrossentropy\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "regressor.compile(loss = \"mse\",\n",
        "         optimizer = Adam(learning_rate=0.001),\n",
        "         metrics=[\"mse\"]                   \n",
        ")\n",
        "callback = [\n",
        "    EarlyStopping(patience=20, restore_best_weights=True),\n",
        "    ModelCheckpoint(\"regressor.h5\", save_best_only=True)\n",
        "]\n",
        "train_history = regressor.fit(x_train, y_train, epochs=100, batch_size=40, validation_data=(x_val,y_val), callbacks=callback)\n",
        "# regressor.fit(x_train, y_train, epochs=40, batch_size=40, validation_split=0.1, callbacks=callback)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHWnwCfqXc9Y"
      },
      "source": [
        "plt.plot(train_history.history[\"loss\"])\n",
        "plt.plot(train_history.history[\"val_loss\"])\n",
        "plt.title(\"Loss Graph\")\n",
        "plt.legend(['loss', 'val_loss'], loc=\"upper left\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_MlX5bxoLC9"
      },
      "source": [
        "x_val = x_val.reshape(-1,past,feature)\n",
        "pre_price = regressor.predict(x_val)\n",
        "pre_price = pre_price.reshape(-1,1)\n",
        "pre_price = Yscaler.inverse_transform(pre_price)\n",
        "y_val = Yscaler.inverse_transform(y_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aoj0t9rbBTu2"
      },
      "source": [
        "# Visualising the results\n",
        "plt.figure(figsize=(14,6))\n",
        "plt.plot(y_val, color = 'red', label = 'Real Banana Price')\n",
        "plt.plot(pre_price, color = 'blue', label = 'Predicted Banana Price')\n",
        "plt.title('Banana Price Prediction')\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Banana Price')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JxdNs6Go1CEc"
      },
      "source": [
        "# Visualising the results\n",
        "plt.figure(figsize=(14,6))\n",
        "plt.plot(y_val[0:100], color = 'red', label = 'Real Banana Price')\n",
        "plt.plot(pre_price[0:100], color = 'blue', label = 'Predicted Banana Price')\n",
        "plt.title('Banana Price Prediction')\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Banana Price')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_DF6GDhW1eHj"
      },
      "source": [
        "# MSE & RMSE 計算\n",
        "# sklearn.metrics.mean_squared_error(y_true, y_pred)\n",
        "# sklearn.metrics.r2_score(y_true, y_pred)\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "MSE = mean_squared_error(y_val, pre_price)\n",
        "RMSE = np.sqrt(MSE)\n",
        "R2 = r2_score(y_val, pre_price)\n",
        "print(f\"MSE value : {MSE}\", f\"\\nRMSE value : {RMSE}\", f\"\\nR2 score value : {R2}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nq0NQeLsvY6V"
      },
      "source": [
        "gg = Xscaler.transform(gg.reshape(-1,feature))\n",
        "gg = gg.reshape(-1,past,feature)\n",
        "gg_pre_price = regressor.predict(gg)\n",
        "# gg_pre_price = pre_price.reshape(-1,1)\n",
        "gg_pre_price = Yscaler.inverse_transform(gg_pre_price)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "feXAloaovpOO"
      },
      "source": [
        "# Visualising the results\n",
        "plt.figure(figsize=(14,6))\n",
        "plt.plot(yy, color = 'red', label = 'Real Banana Price')\n",
        "plt.plot(gg_pre_price, color = 'blue', label = 'Predicted Banana Price')\n",
        "plt.title('Banana Price Prediction')\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Banana Price')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4DM0AyTk_eFo"
      },
      "source": [
        "# Visualising the results\n",
        "plt.figure(figsize=(14,6))\n",
        "plt.plot(yy[0:100], color = 'red', label = 'Real Banana Price')\n",
        "plt.plot(gg_pre_price[0:100], color = 'blue', label = 'Predicted Banana Price')\n",
        "plt.title('Banana Price Prediction')\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Banana Price')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3liRwCOj_tWH"
      },
      "source": [
        "# MSE & RMSE 計算\n",
        "# sklearn.metrics.mean_squared_error(y_true, y_pred)\n",
        "# sklearn.metrics.r2_score(y_true, y_pred)\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "MSE = mean_squared_error(yy, gg_pre_price)\n",
        "RMSE = np.sqrt(MSE)\n",
        "R2 = r2_score(yy, gg_pre_price)\n",
        "print(f\"MSE value : {MSE}\", f\"\\nRMSE value : {RMSE}\", f\"\\nR2 score value : {R2}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NweD7Tl25VN3"
      },
      "source": [
        "RMSE = round(RMSE,2)\n",
        "regressor.save(f\"P={past}_F={day}_RMSE={RMSE}.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}